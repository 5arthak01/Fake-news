{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data extraction from csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = []\n",
    "content = []\n",
    "date = []\n",
    "title = []\n",
    "\n",
    "with open('trydata.csv', 'r', encoding='utf8') as file:\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    for row in reader:\n",
    "        author.append(row[0])\n",
    "        content.append(row[1])\n",
    "        date.append(row[2])\n",
    "        title.append(row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'prathap', 'make', 'drones', 'claims', 'pm', 'modi', 'factcheck', 'drdo?', 'ewastes', 'induct'}, {'indian', 'helicopter', 'video', 'syria', 'viral', 'old', 'nepal', 'shot'}]\n",
      "[{'nm', 'mostly', 'yearold', 'told', 'defence', 'masters', 'indias', 'received', 'narendra', 'havent', 'positionthe', 'several', 'said', 'subscribe', 'ewastes', 'true', 'according', 'tweeted', 'receive', 'higher', 'category', 'work', 'close', 'ministers', 'company', 'getting', 'infographics', 'roundsa', 'organisation', 'application', 'national', 'service', 'emaila', 'grades', 'drds', 'scientists', 'project', 'claiming', 'karnataka', 'unable', 'portal', 'prathap', 'verify', 'keyword', 'depending', 'development', 'it?', 'details', 'thread', 'bit', 'engineering', 'news', 'experience', 'massively', 'social', 'h', 'minister', 'us', 'accomplishments', 'critical', 'subjects', 'alt', 'notifications', 'twitter', 'hashtag', 'email', 'directly', 'requirements', 'science', 'bengalurubased', 'isnt', 'scientist', 'ranging', 'noted', 'sure', 'drones', 'new', 'clarified', 'politician', 'first', 'search', 'postcard', 'asked', 'yet', 'kannada', 'ameeta', 'inducted', 'appointed', 'retweetsthe', 'limited', 'baseless', 'also', 'degree', 'independently', 'false', 'people', 'essential', 'nmenter', 'qualifications', 'relevant', 'worked', 'led', 'year', 'claimed', 'currently', 'drdoevery', 'call', 'posts', 'fake', 'karnatak', 'never', 'recruits', 'working', 'pratap', 'areas', 'however', 'viral', 'media', 'pm', 'cannot', 'reports', 'office', 'recruit', 'entrylevel', 'report', 'till', 'induction', 'specialized', 'recruited', 'offer', 'c', 'suggests', 'b', 'awards', 'class', 'created', 'bjp', 'builds', 'drdo', 'research', 'claim', 'singh', 'drone', 'drdospeaking', 'modi', 'projects', 'credited', 'number', 'prime', 'years', 'address'}, {'territories', 'return', 'address', 'highway', 'even', 'told', 'using', 'image', 'antiaircraft', 'resulting', 'platform', 'tweeta', 'iamurtazakhalid', 'crossed', 'said', 'international', 'subscribe', 'receive', 'watchdog', 'syriain', 'background', 'around', 'hugo', 'nepal', 'audio', 'videos', 'proposalrami', 'one', 'helicopter', 'craziest', 'human', 'invid', 'retweets', 'read', 'risks', 'maarat', 'viewsalt', 'captured', 'control', 'weve', 'iconic', 'today', 'found', 'outlets', 'near', 'northwestern', 'rebels', 'midairregards', 'october', 'entire', 'indian', 'keyword', 'video', 'town', 'posted', 'shows', 'irmaknepal', 'war', 'alnumanthus', 'incident', 'promoted', 'news', 'air', 'social', 'pilot', 'us', 'attracting', 'enter', 'fighting', 'alt', 'notifications', 'twitter', 'email', 'lakhdar', 'rights', 'appeared', 'userregards', 'countryside', 'conduct', 'force', 'brahimi', 'ceasefire', 'damascusaleppo', 'troops', 'setting', 'new', 'dates', 'per', 'midair', 'envoy', 'descends', 'support', 'search', 'fire', 'without', 'user', 'back', 'shot', 'performed', 'idlib', 'border', 'observatory', 'downed', 'also', 'false', 'raged', 'surfaced', 'airstrike', 'syria', 'led', 'alnuman', 'airstrikes', 'clue', 'explodes', 'belahiya', 'rudra', 'opposition', 'khalid', 'posts', 'abdelrahman', 'reverse', 'however', 'hal', 'maaret', 'media', 'viral', 'peace', 'tentative', 'airforces', 'murtaza', 'multiple', 'india', 'verification', 'well', 'warned', 'region', 'telegraph', 'key', 'conflict', 'civil', 'take', 'wrote', 'contacted', 'syrian', 'claim', 'fought', 'head', 'ablaze', 'wednesday', 'syaaf', 'tweet', 'hkaaman', 'second', 'kaaman', 'struck'}]\n"
     ]
    }
   ],
   "source": [
    "def cleaning(rawcontent):\n",
    "    #rawcontent is known to be a list of strings\n",
    "    content=[]\n",
    "    alphabets = set(string.ascii_letters)\n",
    "    endings = set([' ', '!', '?'])\n",
    "\n",
    "    for text in rawcontent:\n",
    "        # for each string \"text\" in rawcontent\n",
    "\n",
    "        clean = \"\"\n",
    "        \n",
    "        # Consider only alphabets and convert them into lowercase, seperated by spaces\n",
    "        for letter in text:\n",
    "            if letter in alphabets:\n",
    "                clean+=letter.lower()\n",
    "            elif letter in endings:\n",
    "                clean+=letter\n",
    "    \n",
    "        # remove words with high occurence but no use\n",
    "        clean = clean.split()\n",
    "        clean=[word for word in clean if word not in stop_words] \n",
    "\n",
    "        content.append(set(clean))\n",
    "    \n",
    "    return content\n",
    "\n",
    "title = cleaning(title)\n",
    "content = cleaning(content)\n",
    "\n",
    "print(title)\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "bjp = ['bjp', 'amit shah', 'narendra modi', 'aadityanath yogi']\n",
    "congress = ['congress', 'inc', 'ncp', 'rahul gandhi', 'sonia gandhi']\n",
    "socialmedia = ['facebook', 'wechat', 'whatsapp', 'instagram', 'twitter', 'youtube', 'qq', 'tumblr', 'reddit', 'tiktok', 'linkedin', 'snapchat', 'pinterest']\n",
    "news = ['aaj tak', 'abp news', 'cnbc', 'ndtv', 'india tv', 'republic bharat', 'news18 india', 'zee news', 'cnn', 'dd india', 'times now', 'bbc']\n",
    "\n",
    "def count(trend):\n",
    "    counter = 0\n",
    "\n",
    "    t = []\n",
    "    for each in trend:\n",
    "        t.extend(each.split())\n",
    "\n",
    "    for x in range(len(content)):\n",
    "        for name in t:\n",
    "            if name in title[x] or name in content[x]:\n",
    "                counter+=1\n",
    "                break \n",
    "    \n",
    "    return counter\n",
    "\n",
    "print(count(socialmedia))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
